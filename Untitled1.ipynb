{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf26a72-671c-4d93-b40e-c6d369716ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "else:\n",
    "    # Otherwise, attempt to discover local credentials as described on https://cloud.google.com/docs/authentication/application-default-credentials\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117dcf93-fe96-4e69-b2fc-58bc58461bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 17:13:43.118666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import backoff\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.exceptions import AlreadyExists\n",
    "from google.cloud import documentai\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "from logging import error\n",
    "import re\n",
    "import textwrap\n",
    "from typing import Tuple, List\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab8ed30-ed75-43da-85ca-019d0a1493fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from set_processor import create_processor, process_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6673f16-63d7-483a-b1e3-917f8ed1429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_extraction_from_pdf import split_and_save_pdf, text_extraction_from_pdf\n",
    "from text_chunking import text_to_sentences, text_to_paragraph, paragraphs_to_df\n",
    "from create_embeddings import get_embedding, get_context_from_question, text_generation_model_with_backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95635069-a67e-49e1-a298-0f12413425bf",
   "metadata": {},
   "source": [
    "## 1. Import validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2135f4f3-e3a6-45af-9dca-578e6c058f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"df_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0f93c-b3fe-49fd-ad97-e979c6097352",
   "metadata": {},
   "source": [
    "## 2. Process given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604284af-564d-4e82-97bf-fa0d797e104a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_number</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Breeze Motor CompanyLimitedRegistered number: ...</td>\n",
       "      <td>[0.002161432756111026, -0.01833339035511017, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5th Floor Merck HouseSeldown LanePooleDorsetBH...</td>\n",
       "      <td>[-0.013716379180550575, -0.015292800031602383,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Group Strategic Report1-5Director's Report6-8I...</td>\n",
       "      <td>[2.6124604119104333e-05, -0.023879574611783028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BREEZE MOTOR COMPANY LIMITEDGROUP STRATEGIC RE...</td>\n",
       "      <td>[0.00749810878187418, -0.02356719598174095, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to look to grow the business where the managem...</td>\n",
       "      <td>[7.044868834782392e-05, 0.0037446788046509027,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>2,656,9222,851,545Bank overdrafts(14,370)14,37...</td>\n",
       "      <td>[0.026068534702062607, -0.0286362636834383, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>351,42630.Pension commitmentsThe Company and G...</td>\n",
       "      <td>[-0.007525721564888954, -0.03144488483667374, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>£££Not later than 1 year1,057,698976,913893,84...</td>\n",
       "      <td>[0.007913406006991863, -0.015880122780799866, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>6,275,7464,501,46732.Other financial commitmen...</td>\n",
       "      <td>[0.00831800140440464, -0.029883651062846184, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>loaned £131,533). The loan was repaid in April...</td>\n",
       "      <td>[-0.013277276419103146, -0.03605133667588234, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paragraph_number                                               text  \\\n",
       "0                   1  Breeze Motor CompanyLimitedRegistered number: ...   \n",
       "1                   2  5th Floor Merck HouseSeldown LanePooleDorsetBH...   \n",
       "2                   3  Group Strategic Report1-5Director's Report6-8I...   \n",
       "3                   4  BREEZE MOTOR COMPANY LIMITEDGROUP STRATEGIC RE...   \n",
       "4                   5  to look to grow the business where the managem...   \n",
       "..                ...                                                ...   \n",
       "109               110  2,656,9222,851,545Bank overdrafts(14,370)14,37...   \n",
       "110               111  351,42630.Pension commitmentsThe Company and G...   \n",
       "111               112  £££Not later than 1 year1,057,698976,913893,84...   \n",
       "112               113  6,275,7464,501,46732.Other financial commitmen...   \n",
       "113               114  loaned £131,533). The loan was repaid in April...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.002161432756111026, -0.01833339035511017, -...  \n",
       "1    [-0.013716379180550575, -0.015292800031602383,...  \n",
       "2    [2.6124604119104333e-05, -0.023879574611783028...  \n",
       "3    [0.00749810878187418, -0.02356719598174095, -0...  \n",
       "4    [7.044868834782392e-05, 0.0037446788046509027,...  \n",
       "..                                                 ...  \n",
       "109  [0.026068534702062607, -0.0286362636834383, -0...  \n",
       "110  [-0.007525721564888954, -0.03144488483667374, ...  \n",
       "111  [0.007913406006991863, -0.015880122780799866, ...  \n",
       "112  [0.00831800140440464, -0.029883651062846184, -...  \n",
       "113  [-0.013277276419103146, -0.03605133667588234, ...  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use on Breeze Motor's report text \n",
    "text = df_companies.iloc[1,5]\n",
    "\n",
    "# 1. Chunk the text into paragraph and transform into a df: when using a size 40, chunk 3 has the relevant info\n",
    "chunk_size = 20\n",
    "sentence_chunks = text_to_paragraph(text, chunk_size)\n",
    "df = paragraphs_to_df(sentence_chunks)\n",
    "# df = df.drop(df.index[-1]) only for index 8 special steel group\n",
    "\n",
    "# 2. Get the embeddings vector using Gecko for each chunk stored in a new column p\n",
    "get_embedding.counter = 0\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: get_embedding(x)) # This may take several minutes to complete.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ee0d0a-b2df-481e-8505-c5ba5847b905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(get_embedding(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda29bdc-183e-461f-9f00-6fb4f6902778",
   "metadata": {},
   "source": [
    "## 3. Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565d45b4-db8a-4722-9e1c-59c897eab77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the scope 1 emissions\n",
      "PaLM Predicted:  The provided context does not mention anything about scope 1 emissions, so I cannot answer this question. \n",
      "\n",
      "\n",
      "    paragraph_number                                               text\n",
      "22                23  20212020Note££Turnover499,000,30077,409,820Cos...\n",
      "89                90  2021Company20202021££££Consignment stock1,330,...\n",
      "87                88  Profit/(Loss)££Breeze (Southampton) Limited1,0...\n",
      "Give me the scope 2 emissions\n",
      "PaLM Predicted:  The provided context does not contain any information about scope 2 emissions. \n",
      "\n",
      "\n",
      "    paragraph_number                                               text\n",
      "89                90  2021Company20202021££££Consignment stock1,330,...\n",
      "22                23  20212020Note££Turnover499,000,30077,409,820Cos...\n",
      "2                  3  Group Strategic Report1-5Director's Report6-8I...\n",
      "Give me the scope 3 emissions\n",
      "PaLM Predicted:  The provided context does not contain any information about scope 3 emissions. \n",
      "\n",
      "\n",
      "    paragraph_number                                               text\n",
      "22                23  20212020Note££Turnover499,000,30077,409,820Cos...\n",
      "2                  3  Group Strategic Report1-5Director's Report6-8I...\n",
      "89                90  2021Company20202021££££Consignment stock1,330,...\n",
      "Give me the total carbon emissions\n",
      "PaLM Predicted:  The context does not mention anything about carbon emissions, so I cannot answer this question from the provided context. \n",
      "\n",
      "\n",
      "    paragraph_number                                               text\n",
      "22                23  20212020Note££Turnover499,000,30077,409,820Cos...\n",
      "76                77  £££Cost585,000 1,911,740 1,207,014473,244281,7...\n",
      "95                96  Payments received on account414,057237,810274,...\n",
      "CPU times: user 105 ms, sys: 17.2 ms, total: 123 ms\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 1 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# df.iloc[2,1] + df.iloc [7,1]\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 2 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 3 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the total carbon emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f284ba2-32c3-4fd0-9b0b-9ddc37c150bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
