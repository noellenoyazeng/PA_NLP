{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba441482-c821-41ed-81b8-203316f6788c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab8ed30-ed75-43da-85ca-019d0a1493fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from set_processor import create_processor, process_document\n",
    "from text_extraction_from_pdf import split_and_save_pdf, text_extraction_from_pdf\n",
    "from text_chunking import text_to_sentences, text_to_paragraph, paragraphs_to_df\n",
    "from create_embeddings import get_embedding, get_context_from_question, text_generation_model_with_backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f5e70-60b6-4f45-89ef-d7ff50e290e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Import validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8861ef-b0f6-4c9c-acc0-d77c6252496e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"df_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0f93c-b3fe-49fd-ad97-e979c6097352",
   "metadata": {},
   "source": [
    "## 2. Text processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "604284af-564d-4e82-97bf-fa0d797e104a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_number</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Breeze Motor CompanyLimitedRegistered number: ...</td>\n",
       "      <td>[0.002161432756111026, -0.01833339035511017, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5th Floor Merck HouseSeldown LanePooleDorsetBH...</td>\n",
       "      <td>[-0.013716379180550575, -0.015292800031602383,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Group Strategic Report1-5Director's Report6-8I...</td>\n",
       "      <td>[2.6124604119104333e-05, -0.023879574611783028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BREEZE MOTOR COMPANY LIMITEDGROUP STRATEGIC RE...</td>\n",
       "      <td>[0.00749810878187418, -0.02356719598174095, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to look to grow the business where the managem...</td>\n",
       "      <td>[7.044868834782392e-05, 0.0037446788046509027,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>2,656,9222,851,545Bank overdrafts(14,370)14,37...</td>\n",
       "      <td>[0.026068534702062607, -0.0286362636834383, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>351,42630.Pension commitmentsThe Company and G...</td>\n",
       "      <td>[-0.007525721564888954, -0.03144488483667374, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>£££Not later than 1 year1,057,698976,913893,84...</td>\n",
       "      <td>[0.007913406006991863, -0.015880122780799866, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>6,275,7464,501,46732.Other financial commitmen...</td>\n",
       "      <td>[0.00831800140440464, -0.029883651062846184, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>loaned £131,533). The loan was repaid in April...</td>\n",
       "      <td>[-0.013277276419103146, -0.03605133667588234, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paragraph_number                                               text  \\\n",
       "0                   1  Breeze Motor CompanyLimitedRegistered number: ...   \n",
       "1                   2  5th Floor Merck HouseSeldown LanePooleDorsetBH...   \n",
       "2                   3  Group Strategic Report1-5Director's Report6-8I...   \n",
       "3                   4  BREEZE MOTOR COMPANY LIMITEDGROUP STRATEGIC RE...   \n",
       "4                   5  to look to grow the business where the managem...   \n",
       "..                ...                                                ...   \n",
       "109               110  2,656,9222,851,545Bank overdrafts(14,370)14,37...   \n",
       "110               111  351,42630.Pension commitmentsThe Company and G...   \n",
       "111               112  £££Not later than 1 year1,057,698976,913893,84...   \n",
       "112               113  6,275,7464,501,46732.Other financial commitmen...   \n",
       "113               114  loaned £131,533). The loan was repaid in April...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.002161432756111026, -0.01833339035511017, -...  \n",
       "1    [-0.013716379180550575, -0.015292800031602383,...  \n",
       "2    [2.6124604119104333e-05, -0.023879574611783028...  \n",
       "3    [0.00749810878187418, -0.02356719598174095, -0...  \n",
       "4    [7.044868834782392e-05, 0.0037446788046509027,...  \n",
       "..                                                 ...  \n",
       "109  [0.026068534702062607, -0.0286362636834383, -0...  \n",
       "110  [-0.007525721564888954, -0.03144488483667374, ...  \n",
       "111  [0.007913406006991863, -0.015880122780799866, ...  \n",
       "112  [0.00831800140440464, -0.029883651062846184, -...  \n",
       "113  [-0.013277276419103146, -0.03605133667588234, ...  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use on Breeze Motor's report text \n",
    "text = df_companies.iloc[1,5]\n",
    "\n",
    "# 1. Chunk the text into paragraph and transform into a df: when using a size 40, chunk 3 has the relevant info\n",
    "chunk_size = 20\n",
    "sentence_chunks = text_to_paragraph(text, chunk_size)\n",
    "df = paragraphs_to_df(sentence_chunks)\n",
    "# df = df.drop(df.index[-1]) only for index 8 special steel group\n",
    "\n",
    "# 2. Get the embeddings vector using Gecko for each chunk stored in a new column p\n",
    "get_embedding.counter = 0\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: get_embedding(x)) # This may take several minutes to complete.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda29bdc-183e-461f-9f00-6fb4f6902778",
   "metadata": {},
   "source": [
    "## 3. Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565d45b4-db8a-4722-9e1c-59c897eab77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 1 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# df.iloc[2,1] + df.iloc [7,1]\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 2 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the scope 3 emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "\n",
    "# your question for the documents\n",
    "question = \"Give me the total carbon emissions\"\n",
    "\n",
    "# get the custom relevant chunks from all the chunks in vector store.\n",
    "context, top_matched_df = get_context_from_question(\n",
    "    question,\n",
    "    vector_store=df,\n",
    "    sort_index_value=3,  # Top N results to pick from embedding vector search\n",
    ")\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "# Call the PaLM API on the prompt.\n",
    "print(question)\n",
    "print(\"PaLM Predicted:\", text_generation_model_with_backoff(prompt=prompt), \"\\n\\n\")\n",
    "# top 5 data that has been picked by model based on user question. This becomes the context.\n",
    "print(top_matched_df)\n",
    "print('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38248767-7f68-48a8-b492-9ac961095661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
