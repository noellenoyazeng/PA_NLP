{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Gen AI Using Python\n",
    "\n",
    "## Overview\n",
    "\n",
    "This **Generative AI Learning Environment** has been configured with the cloud resources and access you would need to get started with experimenting and learning. This notebook presents an introduction to using Google Generative AI foundation models and interacting with them through code. It goes over setting up pre-requisites and demonstrates some basic functionality that has been provided to you within this environment. \n",
    "\n",
    "### Pre-requisites & Recommended Reading\n",
    "\n",
    "- An understanding of Python fundamentals would be good as a starting point to understand the code snippets and functions in this notebook.\n",
    "\n",
    "- The functions in this notebook make use of the Vertex AI SDK for Python which offers an intuitive code interface to interact with Generative AI support on Vertex AI.\n",
    "\n",
    "- Please note that this environment should only be used with **public data** so please ensure that you do not use any prompts based on group data here.\n",
    "\n",
    "Some Recommended Reading:\n",
    "- [Generative AI Support on Google Cloud](https://cloud.google.com/ai/generative-ai)\n",
    "- [Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and Packages\n",
    "\n",
    "In this disconnected environment, you have access to public repositories such as PyPI to install any packages for experimentation and learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user # \"!\" allows you to execute commands on the terminal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Prompts to the Model\n",
    "\n",
    "Google provides its foundation models as API endpoints hosted by them, the Vertex AI SDK provides an abstraction of these API requests so that you can integrate your requests to the models into your code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Google Foundation Model\n",
    "\n",
    "Starting off with importing a model, you have several language models to choose from based on your requirements. In this notebook we are focused on the Text Generation (text-bison) model which is based on Google's [PaLM2](https://ai.google/discover/palm2/) large language model. This model is optimized for text generation.\n",
    "\n",
    "Other language model options include, chat-bison, code-bison and code-gecko. More details can be found [here](https://cloud.google.com/vertex-ai/docs/generative-ai/language-model-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel # Import a model library from the Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\") # Configure your model version here, the model type needs to match the imported model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompts\n",
    "\n",
    "You can use this model for text generation tasks, here is a simple example showing how you can use the model to generate an out of office message template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write me an out of office message\" # The prompt is sent as a string\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text) # The model.predict function sends the request to the model endpoint and returns the response. The max_output_tokens argument determines the max length of the output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the model for more complex tasks like explaining a piece of code. In this example a question and additional context (the Python code) is provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Explain the syntax and functionality of this python function including what it might be used for\n",
    "def test_function(input):\n",
    "    if input % 400 == 0:\n",
    "        return True\n",
    "    elif input % 100 != 0 and input % 4 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\"\"\" # You use multi-line strings to format the prompt to be easily readable.\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Experiences with Generative AI Models\n",
    "\n",
    "The following code demonstrates how you can use Generative AI to build applications and create experiences that are user-friendly and accessible. It makes use of the ipywidgets library which allows for interactive elements to be used from directly within a notebook.\n",
    "\n",
    "- In this code we set up a simple app, using only a few lines of code, that uses Generative AI to give users an idea of what the weather in a particular location would be like at a certain time of the year if they are looking to travel there. As the app uses a direct prompt to the Generative AI model with no simple logic such as if statements, it can support a variety of inputs. Feel free to experiment and get an idea of how the model responds (e.g, try providing a season instead of a month).\n",
    "\n",
    "- You can also improve the functionality of the application with techniques such as one-shot and few-shot prompting, where you give examples of how the model should respond, you can also better ensure that the responses suit your criteria, this is gone into in more detail in the further notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# The following sets up input objects, these refer to the fields and buttons in the interface.\n",
    "input1 = widgets.Text(placeholder=\"Enter a Location (City, Country Etc.)\")\n",
    "input2 = widgets.Text(placeholder=\"Enter a Month\")\n",
    "button = widgets.Button(description=\"Ask\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# This function defines what happens when the button is clicked.\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        location = input1.value # Set the values of location and month from the inputs\n",
    "        month = input2.value\n",
    "        prompt = \"What is the weather typically like in %s in %s? Only this topic in the answer\" % (location,month) # Using a template string to send the model a dynamic prompt from the fields.\n",
    "        print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)\n",
    "\n",
    "# This attaches the button click event to the above function.        \n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display widgets and title of the app.\n",
    "print(\"Travel Weather App\")\n",
    "display(input1,input2,button,output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
