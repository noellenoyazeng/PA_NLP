{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Open Source Gen AI Models within a Jupyter Notebook\n",
    "\n",
    "This notebook explains how you can leverage Google Cloud features including Vertex AI, Cloud compute resources such as GPUs and Cloud Storage to develop using Generative AI models\n",
    "\n",
    "It goes through how to create a GPU enabled notebook instance within your project and run local inference using open-source models available on **HuggingFace**. A notebook such as this can be used as a virtualised environment for various development tasks and the variety of machine configurations available including enterprise grade GPUs allow for flexibility of costs vs concerns such as training performance.\n",
    "\n",
    "<mark>You can refer to the following guide to understand instance confiugration costs: https://cloud.google.com/vertex-ai/pricing#notebooks. Please also make sure to stop or delete instances when not in use to reduce consumption costs as these resources use a pay as you go model so you only pay for resources for the time in which they are provisioned.</mark>\n",
    "\n",
    "**Section 1** of this notebook can be run in this pre-provisioned notebook instance (which is configured without a GPU) to create the GPU enabled notebook, once it is created you can open this user-guide in the GPU enabled notebook to run **Section 2**.\n",
    "\n",
    "**Please run the following cell to setup required variables for <mark>both</mark> sections 1 and 2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Specific Variables\n",
    "PROJECT_ID = !gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID.n\n",
    "SERVICE_ACCOUNT = \"%s-consumer-sa@%s.iam.gserviceaccount.com\"  % (PROJECT_ID,PROJECT_ID)\n",
    "USER_GUIDE_BUCKET = \"gs://gen-ai-%s-user-guide-bucket\" % PROJECT_ID\n",
    "GEN_AI_BUCKET = \"gs://gen-ai-%s-bucket\" % PROJECT_ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Creating a GPU Enabled Vertex AI Workbench Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Pre-Requisites\n",
    "The pre-requisite environment variables are set here. Some are taken directly from the environment in order to deploy the notebook to the right place wheras others can be changed to alter the instance configuration. Some common configuration parameters are provided here.\n",
    "\n",
    "**Configuration:**\n",
    "- INSTANCE_NAME = Name of the instance to be created\n",
    "- MACHINE_TYPE = CPU and RAM configuration of the notebook: https://cloud.google.com/compute/docs/machine-resource\n",
    "- ACCELERATOR_TYPE = Type of GPU (the preset one is the only type available in Europe-West2) you can deploy to europe-west 4 for additional GPU types: https://cloud.google.com/compute/docs/gpus\n",
    "- ACCELERATOR_NO = Number of Attached GPUs\n",
    "- BOOT_DISK_SIZE = Size in GB of the attached persistent disk. You can increase this if you require additional storage.\n",
    "- VM_IMAGE_NAME = Image to use, this determines what libraries and tools (python version etc.) are installed into the notebook. The preset image contains pytorch 2.0 with python version 3.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customisable Variables\n",
    "INSTANCE_NAME = \"gen-ai-gpu-notebook\"\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "ACCELERATOR_NO = 1\n",
    "BOOT_DISK_SIZE = 100\n",
    "VM_IMAGE_NAME = \"pytorch-2-0-gpu-notebooks-v20230925-debian-11-py310\"\n",
    "INSTANCE_LOCATION = \"europe-west2-b\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Notebook Image\n",
    "In order to select the image that you are using to create the notebook you can edit the `VM_IMAGE_NAME` variable. For an explanation of available pre-built images refer to: https://cloud.google.com/vertex-ai/docs/workbench/user-managed/images. You can run the following command within the terminal to get a full list of image names: `gcloud compute images list --project deeplearning-platform-release | grep notebooks`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use gcloud CLI to create a notebook instance\n",
    "\n",
    "The following gcloud command creates a notebook instance and its configuration is determined by the command line flags. This can also be done through the user interface within the cloud console, but you would need to ensure that configuration parameters are set as detailed here.\n",
    "\n",
    "Note: \"!\" before code runs it as terminal command instead of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud notebooks instances create $INSTANCE_NAME\\\n",
    "--machine-type=$MACHINE_TYPE\\\n",
    "--accelerator-type=$ACCELERATOR_TYPE\\\n",
    "--accelerator-core-count=$ACCELERATOR_NO\\\n",
    "--install-gpu-driver\\\n",
    "--boot-disk-size=$BOOT_DISK_SIZE\\\n",
    "--location=$INSTANCE_LOCATION\\\n",
    "--vm-image-project=\"deeplearning-platform-release\"\\\n",
    "--vm-image-name=\"pytorch-2-0-gpu-notebooks-v20230925-debian-11-py310\"\\\n",
    "--network=\"gen-ai-vpc\"\\\n",
    "--subnet=\"gen-ai-vpc-subnet\"\\\n",
    "--subnet-region=\"europe-west2\"\\\n",
    "--metadata=\"idle-timeout-seconds\"=\"18000\",\"startup-script-url\"=\"$USER_GUIDE_BUCKET/userguide_files_copy.sh\"\\\n",
    "--service-account=$SERVICE_ACCOUNT\\\n",
    "--post-startup-script=\"$USER_GUIDE_BUCKET/userguide_files_copy.sh\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Created Notebook\n",
    "\n",
    "Once you are done using the notebook or do not require it anymore. You can run the following cell to delete the notebook instance you created above. Alternatively you can go to the cloud console notebooks page [here](https://console.cloud.google.com/vertex-ai/workbench/user-managed?) and select the checkbox for the relevant notebook and press delete.\n",
    "\n",
    "If this fails due to the command format, run the first cell in this notebook again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud notebooks instances delete $INSTANCE_NAME --location=$INSTANCE_LOCATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Run Inference for Open Source Models from HuggingFace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Libraries\n",
    "\n",
    "As this notebook image comes pre-configured from Google with several common dependencies so you can start working quickly. The diffusers and transformers libraries are developed by HuggingFace and model support can be found here: https://github.com/huggingface/transformers#model-architectures. To get the full list of installed python libararies you can use \"`pip freeze`\" in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install diffusers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Usage Examples\n",
    "\n",
    "### Import Libraries and Download Pre-Trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablecode-completion-alpha-3b-4k\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"stabilityai/stablecode-completion-alpha-3b-4k\",\n",
    "  trust_remote_code=True,\n",
    "  torch_dtype=\"auto\",\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Inference for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"def is_leap_year(year):\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "generation_output = model.generate(input_ids=input_ids, max_new_tokens=32)\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Download Pre-Trained Image Generation Model (Stable Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Inference for Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a landscape painting including mountains and a river at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
